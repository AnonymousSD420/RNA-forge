{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multimolecule  # you must import multimolecule to register models\n",
    "from transformers import pipeline\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multimolecule import RnaTokenizer, RiNALMoModel\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "DATASET_PATH = \"P_distance_dataset_path.pkl\"\n",
    "\n",
    "tokenizer = RnaTokenizer.from_pretrained('multimolecule/rinalmo')\n",
    "model_llm = RiNALMoModel.from_pretrained('multimolecule/rinalmo')\n",
    "model_llm.to(DEVICE)\n",
    "\n",
    "text = [\"UAGCUUAUCAGACUGAUGUUGA\",\"CUGAUG\",\"CUUAUCAGACUGAUGUUG\"]\n",
    "input = tokenizer(text, return_tensors='pt', padding=True)\n",
    "input = input.to(DEVICE)\n",
    "\n",
    "\n",
    "output = model_llm(**input)\n",
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Tuple\n",
    "\n",
    "class RNADataset(Dataset):\n",
    "    def __init__(self, sequences: List[str], distance_maps: List[List[List[float]]]):\n",
    "        self.sequences = sequences\n",
    "        self.distance_maps = distance_maps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        sequence = self.sequences[idx]  # shape: (seq,)\n",
    "        distance_map = self.distance_maps[idx]  # shape: (seq, seq)\n",
    "        return sequence, distance_map\n",
    "\n",
    "\n",
    "def collate_fn(batch: List[Tuple[str, List[List[float]]]]):\n",
    "    sequences = [item[0] for item in batch]\n",
    "    lengths = [len(i) for i in sequences]\n",
    "    \n",
    "    distance_maps_list: List[List[List[float]]] = [item[1] for item in batch]\n",
    "\n",
    "    # token length = seq length + 2 (CLS and SEP tokens)\n",
    "    input_ids = tokenizer(sequences, return_tensors=\"pt\", padding=True).input_ids\n",
    "\n",
    "    max_len = input_ids.shape[1]\n",
    "    padded_distance_maps_list = []\n",
    "    \n",
    "    for distance_maps in distance_maps_list:\n",
    "        distance_maps = torch.tensor(distance_maps)  # shape: (seq, seq)\n",
    "\n",
    "        padded_distance_map = torch.zeros(max_len, max_len)  # shape: (max_len, max_len)\n",
    "        padded_distance_map[\n",
    "            1 : distance_maps.shape[0] + 1, 1 : distance_maps.shape[1] + 1\n",
    "        ] = distance_maps\n",
    "        padded_distance_maps_list.append(padded_distance_map)\n",
    "    \n",
    "    padded_distance_maps = torch.stack(\n",
    "        padded_distance_maps_list\n",
    "    )  # shape: (batch, max_len, max_len)\n",
    "\n",
    "    return input_ids, padded_distance_maps, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dataset = pickle.load(open(DATASET_PATH, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bad_sequence(seq):\n",
    "    # if 90 percent is a single nucleotide\n",
    "\n",
    "    n = [\"A\", \"C\", \"G\", \"U\", \"T\"]\n",
    "    thresh = 0.9\n",
    "    for x in n:\n",
    "        if seq.count(x) > thresh * len(seq):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_distance_maps = []\n",
    "new_sequences = []\n",
    "\n",
    "seen = set()\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = dataset\n",
    "sequences = dataset[\"sequence\"].tolist()\n",
    "\n",
    "distance_maps = dataset[\"distance_matrix\"].tolist()\n",
    "# plot the length distribution of the sequences\n",
    "lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "\n",
    "print(\"Number of sequences:\", len(sequences))\n",
    "\n",
    "\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    if len(sequence) != len(distance_maps[i]):\n",
    "        print(\"Length mismatch\")\n",
    "    #    print(i, sequence, len(sequence), len(distance_maps[i]))\n",
    "        continue\n",
    "    if bad_sequence(sequence):\n",
    "        # print(\"Bad sequence\")\n",
    "        continue\n",
    "\n",
    "    if sequence not in seen:\n",
    "        seen.add(sequence)\n",
    "        new_sequences.append(sequence)\n",
    "        new_distance_maps.append(distance_maps[i])\n",
    "print(\"Number of unique sequences:\", len(new_sequences))    \n",
    "sequences = new_sequences\n",
    "distance_maps = new_distance_maps\n",
    "\n",
    "\n",
    "def min_max_denormalize(normalized_data, min_val, max_val):\n",
    "    # Reverse Min-Max normalization\n",
    "    original_data = normalized_data * (max_val - min_val) + min_val\n",
    "    \n",
    "    return original_data\n",
    "\n",
    "def flatten(data):\n",
    "    return data.flatten()\n",
    "\n",
    "def unflatten(data):\n",
    "    shape = np.sqrt(len(data)).astype(int)\n",
    "    return data.reshape(shape, shape)\n",
    "\n",
    "min_max_stores = []\n",
    "\n",
    "new_distance_maps = []\n",
    "\n",
    "for seq, dmap in zip(sequences, distance_maps):\n",
    "    dmap= np.array(dmap)\n",
    "    flattened_dmap = flatten(dmap)\n",
    "    # normalized_flattened_dmap, min_val, max_val = min_max_normalize(flattened_dmap)\n",
    "    # normalized_dmap = unflatten(normalized_flattened_dmap)\n",
    "    normalized_dmap = unflatten(flattened_dmap)\n",
    "    # min_max_stores.append((min_val, max_val))\n",
    "    new_distance_maps.append(normalized_dmap)\n",
    "\n",
    "distance_maps = new_distance_maps\n",
    "\n",
    "\n",
    "train_sequences, val_sequences, train_maps, val_maps = train_test_split(\n",
    "    sequences, distance_maps, test_size=0.20, random_state=42\n",
    ")\n",
    "print(\"Number of training sequences:\", len(train_sequences))\n",
    "\n",
    "train_dataset = RNADataset(train_sequences, train_maps)\n",
    "val_dataset = RNADataset(val_sequences, val_maps)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_sequences), len(val_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = device\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_difference_matrix(rows: int, cols: int) -> torch.Tensor:\n",
    "    row_indices = torch.arange(rows).unsqueeze(1).expand(-1, cols)  # (rows, cols)\n",
    "    col_indices = torch.arange(cols).unsqueeze(0).expand(rows, -1)  # (rows, cols)\n",
    "    difference_matrix = torch.abs(row_indices - col_indices)  # Absolute difference\n",
    "    return difference_matrix.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=dilation, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = (\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "            if in_channels != out_channels\n",
    "            else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += shortcut  # Residual connection\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction_ratio=16):\n",
    "        super(SqueezeExcitationBlock, self).__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)  # Global average pooling\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction_ratio, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(channels // reduction_ratio, channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self.global_avg_pool(x)\n",
    "        scale = self.fc1(scale)\n",
    "        scale = self.relu(scale)\n",
    "        scale = self.fc2(scale)\n",
    "        scale = self.sigmoid(scale)\n",
    "        return x * scale  # Recalibrate features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceMapPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistanceMapPredictor, self).__init__()\n",
    "        self.bert = model_llm  # Use the globally defined BERT model\n",
    "        self.hidden_size = self.bert.config.hidden_size  # Dynamically fetch hidden size\n",
    "\n",
    "        # Adjust bottleneck projection to dynamically match input size\n",
    "        self.projection = nn.Conv2d(2 * self.hidden_size, 512, kernel_size=1)\n",
    "\n",
    "        # Enhanced convolutional layers with batch normalization, residual connections, and attention\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            ResidualBlock(512, 512, dilation=1),\n",
    "            ResidualBlock(512, 256, dilation=2),  # Multi-scale context with dilation\n",
    "            SqueezeExcitationBlock(256),         # Channel attention\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        for layer in self.conv_layers:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
    "        outputs = self.bert(input_ids)\n",
    "        embeddings = outputs.last_hidden_state  # Shape: (batch, max_len, hidden_size)\n",
    "        max_len = embeddings.size(1)\n",
    "\n",
    "        # Pairwise concatenation\n",
    "        concat_embeddings = torch.cat(\n",
    "            [\n",
    "                embeddings.unsqueeze(2).expand(-1, -1, max_len, -1),\n",
    "                embeddings.unsqueeze(1).expand(-1, max_len, -1, -1),\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )  # Shape: (batch, max_len, max_len, 2 * hidden_size)\n",
    "\n",
    "        # Permute to match convolution input expectations\n",
    "        concat_embeddings = concat_embeddings.permute(0, 3, 1, 2)  # Shape: (batch, 2 * hidden_size, max_len, max_len)\n",
    "\n",
    "        # Reduce dimensionality with bottleneck\n",
    "        concat_embeddings = self.projection(concat_embeddings)\n",
    "\n",
    "        # Apply convolutional layers\n",
    "        output_distance_map = self.conv_layers(concat_embeddings).squeeze(1)  # Shape: (batch, max_len, max_len)\n",
    "\n",
    "        # Mask upper triangle for valid lengths\n",
    "        upper_tri_mask = torch.triu(torch.ones(max_len, max_len, device=DEVICE), diagonal=1)  # Upper triangle mask\n",
    "        distance_map_mask_list = []\n",
    "        for l in lengths:\n",
    "            distance_map_mask = torch.zeros(max_len, max_len, device=DEVICE)\n",
    "            distance_map_mask[1 : l + 1, 1 : l + 1] = 1\n",
    "            distance_map_mask_list.append(distance_map_mask)\n",
    "\n",
    "        distance_map_masks = torch.stack(distance_map_mask_list)  # Shape: (batch, max_len, max_len)\n",
    "        valid_upper_tri_mask = distance_map_masks * upper_tri_mask  # Combine masks\n",
    "\n",
    "        # Extract upper triangle and enforce symmetry\n",
    "        upper_triangle = output_distance_map * valid_upper_tri_mask\n",
    "        symmetric_map = upper_triangle + upper_triangle.transpose(-1, -2)\n",
    "\n",
    "        diag_indices = torch.arange(max_len, device=DEVICE)\n",
    "        symmetric_map[:, diag_indices, diag_indices] = 0.0\n",
    "\n",
    "        # Return symmetric map (loss will propagate naturally)\n",
    "        return symmetric_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r2_score_with_mask(\n",
    "    y_true: torch.Tensor, y_pred: torch.Tensor, lengths\n",
    "):\n",
    "    # y_true: (batch, max_len, max_len)\n",
    "    # y_pred: (batch, max_len, max_len)\n",
    "    # mask: (batch, max_len, max_len)\n",
    "\n",
    "    max_len = y_pred.shape[1]\n",
    "    distance_map_mask_list = []\n",
    "    \n",
    "    for l in lengths:\n",
    "\n",
    "        distance_map_mask = torch.zeros(max_len, max_len)  # shape: (max_len, max_len)\n",
    "        distance_map_mask[\n",
    "            1 : l + 1, 1 : l + 1\n",
    "        ] = 1\n",
    "        distance_map_mask_list.append(distance_map_mask)\n",
    "\n",
    "    \n",
    "    mask = torch.stack(\n",
    "        distance_map_mask_list\n",
    "    )  # shape: (batch, max_len, max_len)\n",
    "\n",
    "\n",
    "\n",
    "    mask = mask.bool()\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    # print(\"post mask shape\", y_true.shape, y_pred.shape)\n",
    "\n",
    "    r2 = 1 - (\n",
    "        torch.sum((y_true - y_pred) ** 2) / torch.sum((y_true - y_true.mean()) ** 2)\n",
    "    )\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the maximum one \n",
    "def compute_pearson_correlation_with_mask(\n",
    "    y_true: torch.Tensor, y_pred: torch.Tensor, lengths\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the Pearson correlation coefficient between y_true and y_pred \n",
    "    using a mask generated from the lengths array.\n",
    "\n",
    "    Args:\n",
    "        y_true: torch.Tensor, ground truth values (batch, max_len, max_len).\n",
    "        y_pred: torch.Tensor, predicted values (batch, max_len, max_len).\n",
    "        lengths: list or array of integers specifying the valid lengths for each batch.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Pearson correlation coefficient.\n",
    "    \"\"\"\n",
    "    # Generate the mask\n",
    "    max_len = y_pred.shape[1]\n",
    "    distance_map_mask_list = []\n",
    "    \n",
    "    for l in lengths:\n",
    "        distance_map_mask = torch.zeros(max_len, max_len)  # shape: (max_len, max_len)\n",
    "        distance_map_mask[1 : l + 1, 1 : l + 1] = 1\n",
    "        distance_map_mask_list.append(distance_map_mask)\n",
    "\n",
    "    mask = torch.stack(distance_map_mask_list).bool()  # shape: (batch, max_len, max_len)\n",
    "\n",
    "    # Apply the mask to y_true and y_pred\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    # Compute the Pearson correlation coefficient\n",
    "    mean_y_true = y_true.mean()\n",
    "    mean_y_pred = y_pred.mean()\n",
    "    \n",
    "    numerator = torch.sum((y_true - mean_y_true) * (y_pred - mean_y_pred))\n",
    "    denominator = torch.sqrt(\n",
    "        torch.sum((y_true - mean_y_true) ** 2) * torch.sum((y_pred - mean_y_pred) ** 2)\n",
    "    )\n",
    "    pearson_correlation = numerator / denominator\n",
    "\n",
    "    return pearson_correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim.adam import Adam\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_proximity_weights(target_matrix: torch.Tensor, alpha: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Creates a proximity weight matrix with inverse power law decay, normalizes it,\n",
    "    and dynamically scales it using the maximum distance and matrix dimensions.\n",
    "\n",
    "    Args:\n",
    "        target_matrix (torch.Tensor): The target distance matrix of shape (1, len, len).\n",
    "        alpha (float): Scaling factor to control the decay rate.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Dynamically scaled weight matrix of shape (1, len, len).\n",
    "    \"\"\"\n",
    "    assert target_matrix.dim() == 3 and target_matrix.size(0) == 1, \\\n",
    "        \"Input target_matrix must have shape (1, len, len)\"\n",
    "    \n",
    "    # Extract the (len, len) matrix\n",
    "    distance_matrix = target_matrix[0]\n",
    "    \n",
    "    # Assign weights using an inverse power law\n",
    "    weights = 1.0 / (1.0 + alpha * distance_matrix)  # Smoother decay\n",
    "\n",
    "    # Set diagonal to 0\n",
    "    diag_indices = torch.arange(distance_matrix.size(0), device=distance_matrix.device)\n",
    "    weights[diag_indices, diag_indices] = 0.0\n",
    "\n",
    "    # Normalize weights by the maximum excluding the diagonal\n",
    "    max_weight = weights.max()\n",
    "    weights /= max_weight\n",
    "\n",
    "    # Dynamically scale weights\n",
    "    max_distance = distance_matrix.max()\n",
    "    matrix_dim = distance_matrix.size(0)\n",
    "    scale_factor = max_distance / matrix_dim\n",
    "    weights *= scale_factor\n",
    "\n",
    "    # Reshape weights back to (1, len, len)\n",
    "    weights = weights.unsqueeze(0)\n",
    "\n",
    "    del distance_matrix, diag_indices, max_weight, max_distance, matrix_dim, scale_factor, alpha\n",
    "    \n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "model = DistanceMapPredictor().to(DEVICE)\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss(reduction=\"none\")  # Weighted loss\n",
    "scaler = GradScaler()\n",
    "\n",
    "BEST_R2 = -1\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    train_loop.set_description(f\"Epoch [{epoch + 1}/{EPOCHS}] - Training\")\n",
    "\n",
    "    model.train()\n",
    "    for input_ids, targets, lengths in train_loop:\n",
    "        # Move data to DEVICE\n",
    "        input_ids = input_ids.to(DEVICE, non_blocking=True)\n",
    "        targets = targets.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, lengths=lengths)\n",
    "            \n",
    "            # During training, compute proximity weights\n",
    "            target_distances = targets  # Assuming targets is the distance matrix\n",
    "            proximity_weights = create_proximity_weights(target_distances).to(DEVICE)\n",
    "\n",
    "            # Compute losses and apply weights\n",
    "            losses = criterion(outputs, targets)\n",
    "            weighted_loss = (losses * proximity_weights).mean()\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(weighted_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += weighted_loss.item()\n",
    "        train_loop.set_postfix(loss=weighted_loss.item())\n",
    "\n",
    "        # Live GPU Memory Usage\n",
    "        allocated_memory = torch.cuda.memory_allocated(DEVICE) / 1e6  # In MB\n",
    "        reserved_memory = torch.cuda.memory_reserved(DEVICE) / 1e6    # In MB\n",
    "        train_loop.set_postfix(\n",
    "            loss=weighted_loss.item(),\n",
    "            gpu_allocated=f\"{allocated_memory:.2f} MB\",\n",
    "            gpu_reserved=f\"{reserved_memory:.2f} MB\"\n",
    "        )\n",
    "\n",
    "        # Detach and clean up tensors to free memory after each batch\n",
    "        del input_ids, targets, outputs, losses, weighted_loss, proximity_weights\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Training Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    r2_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, targets, lengths in val_loader:\n",
    "            input_ids = input_ids.to(DEVICE, non_blocking=True)\n",
    "            targets = targets.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            with autocast():\n",
    "                # Forward pass\n",
    "                outputs = model(input_ids=input_ids, lengths=lengths)\n",
    "                \n",
    "                # Weighted loss calculation\n",
    "                target_distances = targets  # Assuming targets is the distance matrix\n",
    "                proximity_weights = create_proximity_weights(target_distances).to(DEVICE)\n",
    "\n",
    "                # Compute losses and apply weights\n",
    "                losses = criterion(outputs, targets)\n",
    "                weighted_loss = (losses * proximity_weights).mean()\n",
    "\n",
    "            val_running_loss += weighted_loss.item()\n",
    "\n",
    "            # Compute R² score\n",
    "            r2 = compute_r2_score_with_mask(targets.detach(), outputs.detach(), lengths)\n",
    "            r2_scores.append(r2.item())\n",
    "\n",
    "            # Detach and clean up tensors to free memory after each batch in validation\n",
    "            del input_ids, targets, outputs, losses, weighted_loss, proximity_weights\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    average_r2 = np.mean(r2_scores)\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Validation Loss: {val_running_loss / len(val_loader):.4f}, r^2: {average_r2:.4f}\")\n",
    "\n",
    "    import copy\n",
    "    # Save best model if R² improves\n",
    "    if average_r2 > BEST_R2:\n",
    "        BEST_R2 = average_r2\n",
    "        torch.save(model.state_dict(), \"single_rinalmo_r2_64_proximity_mse.pth\")\n",
    "\n",
    "    # Cleanup after epoch to free unused memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Final cleanup after all epochs are complete\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model\n",
    "# torch.save(best_model.state_dict(), \"best_model.pth\")\n",
    "# load the best model\n",
    "best_model = DistanceMapPredictor().to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(\"single_rinalmo_r2_64_proximity_mse.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform inference on the best model\n",
    "best_model.eval()\n",
    "test_loop = tqdm(val_loader, leave=True)\n",
    "test_loop.set_description(f\"Testing\")\n",
    "\n",
    "test_running_loss = 0.0\n",
    "r2_scores = []\n",
    "targets_list = []\n",
    "outputs_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, targets, lengths in test_loop:\n",
    "        input_ids = input_ids.to(device)  # Shape: (batch, max_len)\n",
    "        targets = targets.to(device)  # Shape: (batch, max_len, max_len)\n",
    "        with autocast():\n",
    "            outputs = best_model(\n",
    "                input_ids=input_ids,\n",
    "                lengths=lengths\n",
    "            )  # Shape: (batch, max_len, max_len)\n",
    "\n",
    "            abs_diff = create_difference_matrix(\n",
    "                targets.size(1), targets.size(2)\n",
    "            ).float()\n",
    "            weights = abs_diff**0.5  # Shape: (max_len, max_len)\n",
    "\n",
    "            losses = criterion(outputs, targets)  # Shape: (batch, max_len, max_len)\n",
    "            weighted_loss = losses * weights.to(\n",
    "                device\n",
    "            )  # Shape: (batch, max_len, max_len)\n",
    "            loss = weighted_loss.mean()  # Shape: (1,)\n",
    "\n",
    "        test_running_loss += loss.item()\n",
    "\n",
    "        # Calculate R2 score\n",
    "        r2 = compute_r2_score_with_mask(targets, outputs, lengths)\n",
    "        r2_scores.append(r2.item())\n",
    "\n",
    "        # Store distance maps (outputs and targets) for later comparison and plotting\n",
    "        targets_list.append(targets.cpu())\n",
    "        outputs_list.append(outputs.cpu())\n",
    "\n",
    "# Calculate and print average R2 score\n",
    "average_r2 = np.mean(r2_scores)\n",
    "print(\n",
    "    f\"Average Testing Loss: {test_running_loss / len(val_loader):.4f}, Average R² Score: {average_r2:.4f}\"\n",
    ")\n",
    "\n",
    "# Randomly select 10 distance maps to plot\n",
    "random_indices = random.sample(range(len(targets_list)), 10)\n",
    "\n",
    "# Plotting function for targets vs outputs (predicted)\n",
    "def plot_distance_maps(target, output, idx):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(target, cmap='viridis')\n",
    "    axs[0].set_title(f\"Target Distance Map {idx}\")\n",
    "    axs[1].imshow(output, cmap='viridis')\n",
    "    axs[1].set_title(f\"Predicted Distance Map {idx}\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot 10 randomly selected maps\n",
    "for idx in random_indices:\n",
    "    target_map = targets_list[idx].squeeze().numpy()\n",
    "    output_map = outputs_list[idx].squeeze().numpy()\n",
    "    plot_distance_maps(target_map, output_map, idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_rna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
